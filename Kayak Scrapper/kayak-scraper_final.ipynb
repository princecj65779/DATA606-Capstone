{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74516ecb-318e-4ae2-9172-2693ecd23e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.5.0-py3-none-any.whl (995 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Using cached trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Collecting trio~=0.17\n",
      "  Using cached trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Using cached exceptiongroup-1.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: idna in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (3.1)\n",
      "Collecting sortedcontainers\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: sniffio in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: pycparser in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sortedcontainers, outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed exceptiongroup-1.0.0 h11-0.14.0 outcome-1.2.0 selenium-4.5.0 sortedcontainers-2.4.0 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa3766d-5904-4f4f-a055-7912cbc8be1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.11.1 bs4-0.0.1 soupsieve-2.3.2.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432f72b1-f09d-44cb-a648-40f58526f900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc84ec3-4480-46cf-a253-8e4ec643ae1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-3.8.4-py2.py3-none-any.whl (27 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tqdm in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from webdriver_manager) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from webdriver_manager) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from requests->webdriver_manager) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from requests->webdriver_manager) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from requests->webdriver_manager) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from requests->webdriver_manager) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from tqdm->webdriver_manager) (0.4.4)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-0.21.0 webdriver-manager-3.8.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dfaacc",
   "metadata": {},
   "source": [
    "# <center> Kayak Scraper </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41746800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2fb3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to chromedriver\n",
    "chromedriver_path =  \"C:/Users/Prince Raghuvanshi/Downloads/chromedriver_win32/chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "997ea200-a99a-4440-b03a-e89960584f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_26216/1579610596.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n",
      "C:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_26216/1579610596.py:7: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = r\"C:/Program Files/Google/Chrome/Application/chrome.exe\"\n",
    "chrome_driver_binary = r\"C:/Program Files/Google/Chrome/Application/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n",
    "#driver.get('http://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee435b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launching the driver\n",
    "driver = webdriver.Chrome(chrome_driver_binary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c518ac",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "086a9e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter -1 when done.\n",
      "----------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "From which city?\n",
      " NYC\n",
      "Where to?\n",
      " BOS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "From which city?\n",
      " IAD\n",
      "Where to?\n",
      " LAX\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "From which city?\n",
      " -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Routes:\n",
      "NYC => BOS\n",
      "IAD => LAX\n"
     ]
    }
   ],
   "source": [
    "# get user input for routes\n",
    "sources = []\n",
    "destinations = []\n",
    "print(\"Please enter -1 when done.\")\n",
    "print(\"-\"*10)\n",
    "while True:\n",
    "    sources.append(input(\"From which city?\\n\"))\n",
    "    if \"-1\" in sources: \n",
    "        sources.pop(-1)\n",
    "        break\n",
    "    destinations.append(input(\"Where to?\\n\"))\n",
    "    if \"-1\" in destinations: \n",
    "        sources.pop(-1)\n",
    "        destinations.pop(-1)\n",
    "        break\n",
    "    print(\"-\"*10)\n",
    "\n",
    "print(\"\\nRoutes:\")\n",
    "for i in range(len(sources)):\n",
    "    print(f\"{sources[i]} => {destinations[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "854eb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Start Date, Please use YYYY-MM-DD format only  2022-12-02\n",
      "End Date, Please use YYYY-MM-DD format only  2022-12-05\n"
     ]
    }
   ],
   "source": [
    "# get user input for period (start and end date)\n",
    "start_date = np.datetime64(input('Start Date, Please use YYYY-MM-DD format only '))\n",
    "end_date = np.datetime64(input('End Date, Please use YYYY-MM-DD format only '))\n",
    "days = end_date - start_date\n",
    "num_days = days.item().days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3496081",
   "metadata": {},
   "source": [
    "### Define functions for scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10169a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airlines(soup):\n",
    "    airline = []\n",
    "    airlines = soup.find_all('span',class_='codeshares-airline-names',text=True)\n",
    "    for i in airlines:\n",
    "        airline.append(i.text)\n",
    "    return airline\n",
    "    \n",
    "def get_total_stops(soup):\n",
    "    stops_list = []\n",
    "    stops = soup.find_all('div',class_='section stops')\n",
    "\n",
    "    for i in stops:\n",
    "        for j in i.find_all('span',class_='stops-text'):\n",
    "               stops_list.append(j.text)\n",
    "    return stops_list\n",
    "\n",
    "def get_price(soup):\n",
    "    prices = []\n",
    "    price = soup.find_all('div',class_='Flights-Results-FlightPriceSection right-alignment sleek')\n",
    "\n",
    "    for i in price:\n",
    "        for j in i.find_all('span', class_='price-text'):\n",
    "            prices.append(j.text)\n",
    "    return prices\n",
    "\n",
    "def get_duration(soup):\n",
    "    duration_list = []\n",
    "    duration = soup.find_all('div' , class_='section duration allow-multi-modal-icons')\n",
    "    for i in duration:\n",
    "        for j in i.find_all('div',class_='top'):\n",
    "            duration_list.append(j.text)\n",
    "    return duration_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ac2d4",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a522f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]C:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_26216/4000765959.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n",
      "C:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_26216/4000765959.py:10: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:25<01:16, 25.40s/it]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:44<00:43, 21.84s/it]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:13<00:25, 25.07s/it]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:52<00:00, 28.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully saved NYC => BOS route as NYC_BOS.csv \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:34<01:44, 34.68s/it]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [02:36<02:52, 86.10s/it]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [02:59<00:57, 57.18s/it]"
     ]
    }
   ],
   "source": [
    "for i in range(len(sources)):\n",
    "    column_names = [\"Airline\", \"Source\", \"Destination\",\"Duration\" ,\"Total stops\", \"Price\",\"Date\"]\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    for j in tqdm(range(num_days+1)):\n",
    "        \n",
    "        # close and open driver every 10 days to avoid captcha\n",
    "        if j % 10 == 0:\n",
    "            driver.quit()\n",
    "            #driver = webdriver.Chrome(chrome_driver_binary)#, chrome_options=chromeOptions)\n",
    "            driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n",
    "            \n",
    "        url = f\"https://www.en.kayak.sa/flights/{sources[i]}-{destinations[i]}/{start_date+j}\"\n",
    "        #url = f\"https://www.priceline.com/flights/{sources[i]}-{destinations[i]}/{start_date+j}\"\n",
    "        driver.get(url)\n",
    "        sleep(15)\n",
    "        \n",
    "        # click show more button to get all flights\n",
    "        try:\n",
    "            show_more_button = driver.find_element_by_xpath('//a[@class = \"moreButton\"]')\n",
    "        except:\n",
    "            \n",
    "            # in case a captcha appears, require input from user so that the for loop pauses and the user can continue the\n",
    "            # loop after solving the captcha\n",
    "            input(\"Please solve the captcha then enter anything here to resume scraping.\")\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                show_more_button.click()\n",
    "                driver.implicitly_wait(10)\n",
    "            except:\n",
    "                break\n",
    "    \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        airlines = get_airlines(soup)\n",
    "        total_stops = get_total_stops(soup)\n",
    "        prices = get_price(soup)\n",
    "        duration = get_duration(soup)\n",
    "        df = df.append(pd.DataFrame({\n",
    "            'Airline': airlines,\n",
    "            'Duration': duration,\n",
    "            'Total stops' : total_stops,\n",
    "            'Price' : prices,\n",
    "            'Date' : start_date+j\n",
    "                                    }))\n",
    "        \n",
    "    df['Source'] = sources[i]\n",
    "    df['Destination'] = destinations[i]\n",
    "    df = df.replace('\\n','', regex=True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    # save data as csv file for each route\n",
    "    df.to_csv(f'{sources[i]}_{destinations[i]}.csv',index=False)\n",
    "    print(f\"Succesfully saved {sources[i]} => {destinations[i]} route as {sources[i]}_{destinations[i]}.csv \")\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d8764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8070f53e-b01f-4198-ba4f-0f02928908b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7c71b-e087-43bc-9876-ba0ffe1bd16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
