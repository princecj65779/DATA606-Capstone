{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74516ecb-318e-4ae2-9172-2693ecd23e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Using cached selenium-4.5.0-py3-none-any.whl (995 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Using cached trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Collecting trio~=0.17\n",
      "  Using cached trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Using cached exceptiongroup-1.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: idna in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (3.1)\n",
      "Collecting sortedcontainers\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: sniffio in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Collecting outcome\n",
      "  Using cached outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: pycparser in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sortedcontainers, outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed exceptiongroup-1.0.0 h11-0.14.0 outcome-1.2.0 selenium-4.5.0 sortedcontainers-2.4.0 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa3766d-5904-4f4f-a055-7912cbc8be1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.11.1 bs4-0.0.1 soupsieve-2.3.2.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432f72b1-f09d-44cb-a648-40f58526f900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc84ec3-4480-46cf-a253-8e4ec643ae1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-3.8.4-py2.py3-none-any.whl (27 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tqdm in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from webdriver_manager) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from webdriver_manager) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from requests->webdriver_manager) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from requests->webdriver_manager) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from requests->webdriver_manager) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from requests->webdriver_manager) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\jupyterlab\\resources\\jlab_server\\lib\\site-packages (from tqdm->webdriver_manager) (0.4.4)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-0.21.0 webdriver-manager-3.8.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dfaacc",
   "metadata": {},
   "source": [
    "# <center> Kayak Scraper </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41746800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2fb3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to chromedriver\n",
    "chromedriver_path =  \"C:/Users/Prince Raghuvanshi/Downloads/chromedriver_win32/chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997ea200-a99a-4440-b03a-e89960584f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_26216/1579610596.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n",
      "C:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_26216/1579610596.py:7: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = r\"C:/Program Files/Google/Chrome/Application/chrome.exe\"\n",
    "chrome_driver_binary = r\"C:/Program Files/Google/Chrome/Application/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n",
    "#driver.get('http://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee435b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launching the driver\n",
    "driver = webdriver.Chrome(chrome_driver_binary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c518ac",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "086a9e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter -1 when done.\n",
      "----------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "From which city?\n",
      " NYC\n",
      "Where to?\n",
      " LAX\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "From which city?\n",
      " -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Routes:\n",
      "NYC => LAX\n"
     ]
    }
   ],
   "source": [
    "# get user input for routes\n",
    "sources = []\n",
    "destinations = []\n",
    "print(\"Please enter -1 when done.\")\n",
    "print(\"-\"*10)\n",
    "while True:\n",
    "    sources.append(input(\"From which city?\\n\"))\n",
    "    if \"-1\" in sources: \n",
    "        sources.pop(-1)\n",
    "        break\n",
    "    destinations.append(input(\"Where to?\\n\"))\n",
    "    if \"-1\" in destinations: \n",
    "        sources.pop(-1)\n",
    "        destinations.pop(-1)\n",
    "        break\n",
    "    print(\"-\"*10)\n",
    "\n",
    "print(\"\\nRoutes:\")\n",
    "for i in range(len(sources)):\n",
    "    print(f\"{sources[i]} => {destinations[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "854eb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Start Date, Please use YYYY-MM-DD format only  2023-01-01\n",
      "End Date, Please use YYYY-MM-DD format only  2023-01-03\n"
     ]
    }
   ],
   "source": [
    "# get user input for period (start and end date)\n",
    "start_date = np.datetime64(input('Start Date, Please use YYYY-MM-DD format only '))\n",
    "end_date = np.datetime64(input('End Date, Please use YYYY-MM-DD format only '))\n",
    "days = end_date - start_date\n",
    "num_days = days.item().days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3496081",
   "metadata": {},
   "source": [
    "### Define functions for scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10169a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airlines(soup):\n",
    "    airline = []\n",
    "    airlines = soup.find_all('span',class_='codeshares-airline-names',text=True)\n",
    "    for i in airlines:\n",
    "        airline.append(i.text)\n",
    "    return airline\n",
    "    \n",
    "def get_total_stops(soup):\n",
    "    stops_list = []\n",
    "    stops = soup.find_all('div',class_='section stops')\n",
    "\n",
    "    for i in stops:\n",
    "        for j in i.find_all('span',class_='stops-text'):\n",
    "               stops_list.append(j.text)\n",
    "    return stops_list\n",
    "\n",
    "def get_price(soup):\n",
    "    prices = []\n",
    "    price = soup.find_all('div',class_='Flights-Results-FlightPriceSection right-alignment sleek')\n",
    "\n",
    "    for i in price:\n",
    "        for j in i.find_all('span', class_='price-text'):\n",
    "            prices.append(j.text)\n",
    "    return prices\n",
    "\n",
    "def get_duration(soup):\n",
    "    duration_list = []\n",
    "    duration = soup.find_all('div' , class_='section duration allow-multi-modal-icons')\n",
    "    for i in duration:\n",
    "        for j in i.find_all('div',class_='top'):\n",
    "            duration_list.append(j.text)\n",
    "    return duration_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ac2d4",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a522f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_26216/4000765959.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n",
      "C:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_26216/4000765959.py:10: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:39<01:19, 39.59s/it]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:59<00:28, 28.08s/it]"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please solve the captcha then enter anything here to resume scraping. i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:19<00:00, 26.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully saved NYC => LAX route as NYC_LAX.csv \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sources)):\n",
    "    column_names = [\"Airline\", \"Source\", \"Destination\",\"Duration\" ,\"Total stops\", \"Price\",\"Date\"]\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    for j in tqdm(range(num_days+1)):\n",
    "        \n",
    "        # close and open driver every 10 days to avoid captcha\n",
    "        if j % 10 == 0:\n",
    "            driver.quit()\n",
    "            #driver = webdriver.Chrome(chrome_driver_binary)#, chrome_options=chromeOptions)\n",
    "            driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)\n",
    "            \n",
    "        url = f\"https://www.en.kayak.sa/flights/{sources[i]}-{destinations[i]}/{start_date+j}\"\n",
    "        #url = f\"https://www.priceline.com/flights/{sources[i]}-{destinations[i]}/{start_date+j}\"\n",
    "        driver.get(url)\n",
    "        sleep(15)\n",
    "        \n",
    "        # click show more button to get all flights\n",
    "        try:\n",
    "            show_more_button = driver.find_element_by_xpath('//a[@class = \"moreButton\"]')\n",
    "        except:\n",
    "            \n",
    "            # in case a captcha appears, require input from user so that the for loop pauses and the user can continue the\n",
    "            # loop after solving the captcha\n",
    "            input(\"Please solve the captcha then enter anything here to resume scraping.\")\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                show_more_button.click()\n",
    "                driver.implicitly_wait(10)\n",
    "            except:\n",
    "                break\n",
    "    \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        airlines = get_airlines(soup)\n",
    "        total_stops = get_total_stops(soup)\n",
    "        prices = get_price(soup)\n",
    "        duration = get_duration(soup)\n",
    "        df = df.append(pd.DataFrame({\n",
    "            'Airline': airlines,\n",
    "            'Duration': duration,\n",
    "            'Total stops' : total_stops,\n",
    "            'Price' : prices,\n",
    "            'Date' : start_date+j\n",
    "                                    }))\n",
    "        \n",
    "    df['Source'] = sources[i]\n",
    "    df['Destination'] = destinations[i]\n",
    "    df = df.replace('\\n','', regex=True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    # save data as csv file for each route\n",
    "    df.to_csv(f'{sources[i]}_{destinations[i]}.csv',index=False)\n",
    "    print(f\"Succesfully saved {sources[i]} => {destinations[i]} route as {sources[i]}_{destinations[i]}.csv \")\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8070f53e-b01f-4198-ba4f-0f02928908b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Downloads/flight-price-prediction-main/flight-price-prediction-main/NYC_LAX.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PRINCE~1\\AppData\\Local\\Temp/ipykernel_26216/391986616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloads/flight-price-prediction-main/flight-price-prediction-main/NYC_LAX.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\JupyterLab\\resources\\jlab_server\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\JupyterLab\\resources\\jlab_server\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\JupyterLab\\resources\\jlab_server\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\JupyterLab\\resources\\jlab_server\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\JupyterLab\\resources\\jlab_server\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\JupyterLab\\resources\\jlab_server\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\JupyterLab\\resources\\jlab_server\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\JupyterLab\\resources\\jlab_server\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Downloads/flight-price-prediction-main/flight-price-prediction-main/NYC_LAX.csv'"
     ]
    }
   ],
   "source": [
    "lax=pd.read_csv('Downloads/flight-price-prediction-main/flight-price-prediction-main/NYC_LAX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7c71b-e087-43bc-9876-ba0ffe1bd16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
